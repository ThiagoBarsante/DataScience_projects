{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 2 - build machine learning models with Python\n",
    "- The model with best results (higher RECALL metric) was the GBM using sklearn\n",
    "- Detailed information could be seen in previous notebooks - build machine learning models with Python - 1 to 5\n",
    "- This notebook will provide the final python script for deployment along with rules to run the GBM machine learning model\n",
    "\n",
    "\n",
    "\n",
    "### Sample execution of new prediction - execution of 1 python script with new_data as a .csv file\n",
    " \n",
    "#### Detailed data pipeline process \n",
    "\n",
    "- Load the GBM model export in the last notebook\n",
    "- Load the statistics information applied during the GBM model build\n",
    "- Apply the data pipeline rules to new data (standard scale and one hot encode for categorical features)\n",
    "- Run predictions and check the results\n",
    "\n",
    "#### The cell below just show all code in the python script - python_prediction_customer_churn.py that executes the prediction\n",
    "- Load the script with command %load python_prediction_customer_churn.py\n",
    "- All lines were commented "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load python_prediction_customer_churn.py\n",
    "\n",
    "\n",
    "## python script\n",
    "## python_prediction_customer_churn.py <dir/file_name>\n",
    "\n",
    "# ## Load ML models\n",
    "# import pickle\n",
    "# import pandas as pd\n",
    "# import os\n",
    "# import sys\n",
    "\n",
    "# # a = os.getcwd()\n",
    "# def f_validation_process():\n",
    "#     print()\n",
    "#     print('---- Error..')\n",
    "#     print('-----------  Run the program with valid file name for new predictions')\n",
    "#     print()\n",
    "#     print('python python_prediction_customer_churn.py <dir/filename>')\n",
    "#     print()\n",
    "    \n",
    "#     raise ValueError('Re-start the process with correct parameter:filename.')\n",
    "\n",
    "# if (len(sys.argv) != 2):\n",
    "#     f_validation_process()\n",
    "    \n",
    "# ## Load GBM Model - prod model\n",
    "# file_export_model = './ML_models/model_GBM_prod_v1.sav'\n",
    "# gbm_prod_model = pickle.load(open(file_export_model, 'rb'))\n",
    "\n",
    "# # ## New Data for prediction\n",
    "# # df_new_prediction = pd.read_csv('./ML_models/pred_baseline_example.csv')\n",
    "\n",
    "# # df_new_prediction.head(3)\n",
    "\n",
    "# ## check if file exist and load the data\n",
    "# # path_pred_file = './ML_models/new_data_customer_churn.csv'\n",
    "# path_pred_file = sys.argv[1]\n",
    "\n",
    "# if not(os.path.isfile(path_pred_file)):\n",
    "#     print('Inform a correct file path. Sample: ./data/file_name.csv')\n",
    "#     raise('Invalid file name')\n",
    "# else:\n",
    "#     print('Processing file...')\n",
    "#     df_new_prediction = pd.read_csv(path_pred_file)\n",
    "#     df_export_prediction = df_new_prediction.copy()\n",
    "#     # df_new_prediction.head(2)\n",
    "\n",
    "# ## Load statistics information from training data during the ML build and cols orders used for prediction\n",
    "# stats = pd.read_csv('./ML_models/stats_df_train.csv', index_col=0)\n",
    "# cols_prediction = stats.columns.to_list()\n",
    "# cols_std = ['tenure', 'MonthlyCharges' , 'TotalCharges'] ## specific cols to apply scale\n",
    "# stats = stats.T\n",
    "# stats = stats[stats.index.isin(cols_std) ]\n",
    "\n",
    "# ## StandardScale_x aux function\n",
    "# def std_scale_x(x):\n",
    "#     \"\"\" This function will standard scale based on training data\n",
    "#         Only specific cols ['tenure', 'MonthlyCharges' , 'TotalCharges']\n",
    "#     \"\"\"\n",
    "#     return (x - stats['mean']) / stats['std']\n",
    "\n",
    "# ## Apply all rules in the data and run the prediction\n",
    "# std_cols = ['tenure', 'MonthlyCharges' , 'TotalCharges']\n",
    "# cat_cols = [col for col in df_new_prediction.columns.to_list() if col not in std_cols]\n",
    "\n",
    "# ## Apply scale\n",
    "# df_new_std_cols = std_scale_x(df_new_prediction[std_cols])\n",
    "\n",
    "# ## Apply OHE and merge the data\n",
    "# df_categorical = df_new_prediction[cat_cols]\n",
    "# df_new_pred2 = pd.concat([df_new_std_cols, df_categorical], ignore_index=False, axis=1)\n",
    "# df_new_pred2 = pd.get_dummies(df_new_pred2, columns=cat_cols)\n",
    "\n",
    "# ## Include all columns missing to run the prediction\n",
    "# cols_OHE = [x for x in cols_prediction if x not in df_new_pred2.columns.to_list()]\n",
    "# for col in cols_OHE:\n",
    "#     df_new_pred2[col] = 0\n",
    "\n",
    "# df_new_pred2 = df_new_pred2[cols_prediction]\n",
    "\n",
    "# ## Sample data for prediction\n",
    "# # df_new_pred2\n",
    "\n",
    "# # Run prediction and check the result\n",
    "# X_prediction = df_new_pred2.values\n",
    "# y_pred_gbm_prod = gbm_prod_model.predict(X_prediction)\n",
    "# prediction_result = lambda x: 'Churn' if x == 1 else 'No Churn'\n",
    "# # print('Sample of 1 Customer prediction: ', prediction_result(y_pred_gbm_prod))\n",
    "# # y_pred_results = prediction_result(y_pred_gbm_prod)\n",
    "# df_new_pred2['Churn_prediction'] = y_pred_gbm_prod\n",
    "# df_export_prediction['Churn_prediction'] = df_new_pred2['Churn_prediction'].apply(prediction_result)\n",
    "\n",
    "# ## export results \n",
    "# df_export_prediction.to_csv('./ML_models/Churn_prediction_results.csv', sep=',', index_label=False)\n",
    "# print('Prediction done!')\n",
    "# print('  - Check results in the file: Churn_prediction_results.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running new predictions - customer churn\n",
    "- Deployment done with 1 single script : python_prediction_customer_churn.py\n",
    "- Inform the file name as a parameter for the script\n",
    "\n",
    "### The example below show the execution and the results provided"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file...\n",
      "Prediction done!\n",
      "  - Check results in the file: Churn_prediction_results.csv\n",
      "Wall time: 2.51 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "!python python_prediction_customer_churn.py ./ML_models/new_data_customer_churn.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Churn predicitons generated in the .csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tenure,MonthlyCharges,TotalCharges,gender,PaymentMethod,Contract,Churn_prediction\n",
      "185,1,24.8,24.8,Female,Electronic check,Month-to-month,Churn\n",
      "2715,41,25.25,996.45,Male,Bank transfer (automatic),Month-to-month,No Churn\n"
     ]
    }
   ],
   "source": [
    "!head -n 3 ./ML_models/Churn_prediction_results.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "- With the information provided in this Advanced Analytics process many actions can be implemented to retain these customers that will probably churn\n",
    "- The next and final notebook will show some additional considerations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
